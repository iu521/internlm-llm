# 课程笔记
## 模型介绍

书生 浦语2.0（InterLM2）包含三个模型版本

7B：为了轻量级的研究和应用提供了一个轻量但性能不俗的模型
20B: 模型的综合性能更加强劲，可以有效支持更加复杂的食用场景

InterLM2-Chat 在base基础上，经过SFT和RLHF，面向对话进行优化，具有很好的指令遵循，共情聊天和调用工具等能力

InterLM2：在大部分应用中考虑选用的优秀基座。


# 模型能力：
AI助手能力  
人文对话  
文学创作   
工具调用  
内生计算（不需要借助外部计算器）  
代码解释器  
数据分析


## 大模型开发应用流程
![alt text](image-1.png)


## 全链路开源

数据 -> 预训练 -> 微调 ->  部署 -> 评测 -> 应用

### 数据  
开放高质量数据集，数据集获取：https://opendatalab.org.cn/


### 微调
#### 增量训练
使用场景：让基座模型学习到一些新知识，如某个垂类领域的知识
训练数据：文章，书籍，代码等

#### 有监督微调
使用场景：让模型学会理解各种指令进行对话，或者注入少量领域知识
训练数据：高字量对话，问答数据

微调框架：XTuner

### 模型评测
大模型评测 compassKit

1. 数据污染检查
2. 长文本能力评测
3. 中英双语主管评测
4. 支持LMDeploy、vLLM、LighLLM等推理后端

compassHub： 大模型评测社区

### 智能体框架：

Lagent

支持ReAct，ReWoo，AutoGPT 


AgentLego: 多模态智能体工具箱 
_____________________________________________________
_____________________________________________________
学习InternLM2 Technical Report
### 1.摘要

   在4K上做初始化训练，32K上做进一步的预训练与微调，并且在200k的测试中也表现良好。
### 2.介绍
   开源1.8B, 7B, 20B  
   200k的上下文窗口  
   创新RLHF技术（Conditional Online RLHF）
### 3.预训练
   在预训练阶段，数据主要是中英文的书籍，网页，技术资料。其中英文的网页数据是主要的，其中英文网页数据67.51%，中文网页数据18.95%。      
   其中中文数据过滤了广告。    
   代码数据同样考虑到训练打分器，对代码做打分，其中代码质量中等的会给标注员标注后重新训练。  
   #### 数据管道  
   1. 长度选择，基于规则选择32k以上的
   2. 基于统计特征去除不合适的数据
   3. 困惑度选择，衡量文本的一致性，过滤掉干扰文本，

   使用AdamW优化器，我们使用余弦学习率的衰减和学习率的衰减到其最大值的10%。

   预训练分阶段：  
   在第一阶段，我们使用了长度不超过4k的预训练语料库。

   在第二阶段，我们纳入了50%的长度不超过32k的训练前语料库。

   在第三个阶段，我们使用了特定于能力的增强数据。在每个阶段，我们用英语、中文和代码混合数据。
### 4. 对齐
   #### SFT
   SFT中使用任务包括：NLP 任务，数学，代码，安全，对话，函数调用。

   其中主要是对话（50.37%），NLP任务（16.57%），数学（18.23%）。

   #### Conditional reward model

   传统的方法通常依赖于多个偏好模型来解决不同领域之间的偏好冲突
   ![alt text](image.png)
   从图片看，确实是一个从两个奖励模型变为一个奖励模型，但是多出了不少的系统提示，用不同的提示产生不同的偏好反馈效果。以前是一个偏好任务训练一个模型，现在是通过系统提示词改变模型，有点类似prefix learning。

   改变传统的Focal Loss, 添加衰减来防止模型对于容易样本的过拟合，

   看完，感觉工程量惊人。大模型强者，恐怖如斯。


